% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tune_gbm.R
\name{tune_gbm}
\alias{tune_gbm}
\title{Function for constructing Generalized Boosted Regression models with exploration of hyper-parameters}
\usage{
tune_gbm(
  data,
  response,
  predictors,
  predictors_f = NULL,
  partition,
  grid = NULL,
  thr = NULL,
  metric = "TSS",
  ...
)
}
\arguments{
\item{data}{data.frame. Database with response (0,1) and predictors values.}

\item{response}{character. Column name with species absence-presence data (0,1).}

\item{predictors}{character. Vector with the column names of quantitative predictor variables (i.e. continuous or discrete variables). Usage predictors = c("aet", "cwd", "tmin")}

\item{predictors_f}{character. Vector with the column names of qualitative predictor variables (i.e. ordinal or nominal variables type). Usage predictors_f = c("landform")}

\item{partition}{character. Column name with training and validation partition groups.}

\item{grid}{data.frame. Provide a data frame object with algorithm hyper-parameters values to be tested. It Is recommended to generate this data.frame with grid() function. Hyper-parameters needed for tuning are 'n.trees', 'shrinkage', and 'n.minobsinnode'.}

\item{thr}{character. Threshold used to get binary suitability values (i.e. 0,1). It is useful for threshold-dependent performance metrics. It is possible to use more than one threshold type. It is necessary to provide a vector for this argument. The next threshold area available:
\itemize{
  \item LPT: The highest threshold at which there is no omission. Usage thr=c(type='LPT').
  \item EQUAL_SENS_SPEC: Threshold at which the sensitivity and specificity are equal.
  \item MAX_TSS: Threshold at which the sum of the sensitivity and specificity is the highest.
  Usage thr=c(type='MAX_TSS').
  \item MAX_KAPPA: The threshold at which kappa is the highest ("max kappa"). Usage thr=c(type='MAX_KAPPA').
  \item MAX_JACCARD: The threshold at which Jaccard is the highest. Usage thr=c(type='MAX_JACCARD').
  \item MAX_SORENSEN: The threshold at which Sorensen is highest. Usage thr=c(type='MAX_SORENSEN').
  \item MAX_FPB: The threshold at which FPB is highest. Usage thr=c(type='MAX_FPB').
  \item SENSITIVITY: A threshold value specified by user. Usage thr=c(type='SENSITIVITY', sens='0.6'). 'sens' refers to models will be binarized using this suitability value.
  }}

\item{metric}{character. Performance metric used for selecting the best combination of hyper-parameter values. Can be used one of the next metrics SORENSEN, JACCARD, FPB, TSS, KAPPA, AUC, and BOYCE. TSS is used as default.}
}
\value{
A list object with:
\itemize{
\item model: A "gbm" class object. This object can be used for predicting.
\item tune_performance: Performance metric (see \code{\link{enm_eval}}) for each combination of the hyper-parameters.
\item best_hyper: Hyper-parameters values and performance metric (see \code{\link{enm_eval}}) for the best hyper-parameters combination.
\item selected_threshold: Value of the threshold selected.
\item threshold_table: Value of all threshold.
}
}
\description{
Function for constructing Generalized Boosted Regression models with exploration of hyper-parameters
}
\examples{
\dontrun{
data(abies_db)
abies_db

# We will partition the data with the k-fold method

abies_db2 <- data_part(
  data = abies_db,
  p_a = "pr_ab",
  bg_data = NULL,
  bg_a = NULL,
  method = c(method = "KFOLD", folds = 10)
)

# pr_ab columns is species presence and absences (i.e. the response variable)
# partition is columns with partition groups for performing 5-fold cross validation
# from aet to landform are the predictors variables (landform is a qualitative variable)

# Hyper-parameter values for tuning
tune_grid <-
  expand.grid(
    n.trees = c(20, 50, 100, 200),
    shrinkage = c(0.1, 0.5, 1),
    n.minobsinnode = c(1, 3, 5, 7, 9)
  )

gbm_t <-
  tune_gbm(
    data = abies_db2,
    response = "pr_ab",
    predictors = c(
      "aet", "cwd", "tmin", "ppt_djf",
      "ppt_jja", "pH", "awc", "depth", "percent_clay"
    ),
    predictors_f = c("landform"),
    partition = "partition",
    grid = tune_grid,
    thr = "MAX_TSS",
    metric = "TSS",
  )

# Outputs
gbm_t$model
gbm_t$tune_performance
gbm_t$best_hyper
gbm_t$selected_threshold
gbm_t$threshold_table

# Graphical exploration of performance of each hyper-parameter setting
require(ggplot2)
ggplot(gbm_t$tune_performance, aes(n.minobsinnode, TSS_mean)) +
  geom_point(aes(col = factor(n.trees)))

pg <- position_dodge(width = 0.5)
ggplot(gbm_t$tune_performance, aes(factor(n.minobsinnode),
  TSS_mean,
  col = factor(shrinkage)
)) +
  geom_errorbar(aes(ymin = TSS_mean - TSS_sd, ymax = TSS_mean + TSS_sd), width = 0.2, position = pg) +
  geom_point(position = pg) +
  geom_line(
    data = gbm_t$tune_performance,
    aes(as.numeric(factor(n.minobsinnode)),
      TSS_mean,
      col = factor(shrinkage)
    ), position = pg
  ) +
  facet_wrap(. ~ n.trees) +
  theme(legend.position = "bottom")
}

}
\seealso{
\code{\link{tune_mx}}, \code{\link{tune_nnet}}, \code{\link{tune_rf}}, and \code{\link{tune_svm}}.
}
\concept{aggregate functions}
